---
title: "Brickman Walkthrough"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Table of Contents**

* [Overview](#overview)
* [Data preparation](#data-preparation)
* [Modeling](#modeling)
* [Model Evaluation](#model-evaluation)
* [Predictions and Plots](#predictions-and-plots)

This repository contains resources a walkthrough for modeling presence/absence data using North Atlantic covariates from [Brickman et. al. 2021](https://online.ucpress.edu/elementa/article/9/1/00055/116900/Projections-of-physical-conditions-in-the-Gulf-of). Files included in this repository are: 

* **README.md** (this document): Overview and walkthrough of Brickman modeling process 
* **brickman_walkthrough.R**: the complete R code used in the modeling walkthrough
* **brickman_walkthrough_help.R**: code for three helper functions meant to assist with generating predictions and plots

## Overview ##

The Brickman dataset consists of environmental covariates for a variety of climate scenarios in the North Atlantic. Covariates were generated by downscaling low-resolution IPCC data to a much higher 1/12 degree resolution. The Brickman dataset contains high resolution datasets for present day (2015), 2055, and 2075 for RCP 45 and 85 conservation scenarios. Environmental covariates available include bathymetry, bottom stress, mixed layer depth, sea surface / sea bottom temperature and salinity, and current vectors.  

**Brickman coordinate bounding box:**

 xmin   xmax  ymin  ymax 
 
-101.5 -24.5  16.0  75.2 

This walkthrough provides a guide for building a presence/absence model using the Brickman dataset. By training a model with present-day covariates, we can generate high resolution predictions for the four available future climate scenarios. This code is beginner-friendly and can perform the entire modeling process for a provided dataset, but to improve and modify the model or predictions more coding experience may be required. 

* This code is for building a model that takes month as a covariate. Predicted output is on a monthly basis. Building an annual model is possible, but requires some changes to brickman variable extraction. 
* All code must be run within Bigelow's ecocast server. 
* This walkthrough makes use of the base R pipe operator, [`|>`](https://www.infoworld.com/article/3621369/use-the-new-r-pipe-built-into-r-41.html). 
* Questions? Comments? Contact me by email at ojohnson@bigelow.org

**Required Packages**
```{r, message = FALSE}
# for modeling and loading packages such as dplyr, purrr, and ggplot2
library(tidymodels) 
# for handling Brickman data 
library(stars) 
library(brickman) 
# for plotting 
library(viridis)
```

\* *The `brickman` package was written by Ben Tupper and is available on ecocast and [GitHub](https://github.com/BigelowLab/brickman).*

## Data Preparation ##

```{r}
set.seed(607)
```

To begin, choose your desired presence/absense data and assign it to `pa_data`. The data should be an `sf` object (crs 4326) and have the following columns: 

* `PRESENCE`: factor, either 0 or 1
* `MONTH`: numeric, 1 through 12

Make sure that all datapoints in `pa_data` are within the Brickman coordinate bounding box. To convert a dataframe to `sf`, use [`st_as_sf()`](https://www.rdocumentation.org/packages/sf/versions/1.0-7/topics/st_as_sf). 

For the walkthrough, we will be using *C. Finmarchicus* data collected from the [Ecomon survey](https://www.st.nmfs.noaa.gov/copepod/data/us-05101/index.html). We will consider *C. Finmarchicus* present if there are more than 10,000 individuals per square meter. 

```{r}
library(ecomon) # not needed if not working with ecomon data

pa_data <- ecomon::read_staged(species = "calfin", form = "sf") |>
  transmute(PRESENCE = (total_m2 > 10000) |> as.numeric() |> as.factor(),
            MONTH = lubridate::month(date))

pa_data
```

Next, define `VARS`, the list of Brickman environmental covariates to include in the modelling process. A complete list of available covariates is below: subset this as you desire.

* `Bathy_depth`: bathymetry
* `Xbtm`: bottom stress
* `MLD`: mixed layer depth
* `Sbtm`, `Tbtm`: sea bottom salinity, temperature
* `SSS`, `SST`: sea surface salinity, temperature
* `U`, `V`: horizontal and vertical current velocity

```{r}
# COVARIATES
VARS <- c("Bathy_depth", "Xbtm", "MLD", "Sbtm", "SSS", "SST", "Tbtm", "U", "V")
```

Finally, use the `brickman::extract_points()` method to match `pa_data` to present-day Brickman covariates and create the testing/training data for the model. 

* `pa_data` is matched to Brickman data by extracting covariates from the geographically closest Brickman datapoint. 

```{r}
# pairing brickman present data to presence data - this is the input dataset
model_data <- brickman::extract_points(brickman::compose_filename("PRESENT"), 
                                       vars = VARS, 
                                       pts = pa_data, 
                                       complete = TRUE,
                                       simplify_names = TRUE) |>
  # binding the original dataset and selecting needed columns
  bind_cols(pa_data) |>
  select(lat, lon, PRESENCE, MONTH, all_of(VARS)) |>
  rowwise() |>
  # variables are returned as a list with monthly values ~ extract correct month
  mutate_at(VARS[!VARS == "Bathy_depth"], ~.x[[MONTH]]) |>
  ungroup() |>
  # to treat month as a continuous variable remove this line
  mutate(MONTH = as.factor(MONTH)) 

model_data
```

## Modeling ##

Next, use `Tidymodels` to build a `workflow` object modeling `model_data`. An example workflow is below, but feel free to change recipes, models, or splitting techniques as desired. 

* The example recipe converts `U` and `V` to a single `Vel` attribute representing overall current velocity. 
* For more information on modeling with `Tidymodels`, check out my [`Tidymodels Tutorial`](https://oj713.github.io/tidymodels/). 

```{r}
# performing initial split 
data_split <- initial_split(model_data, prop = 3/4, strata = PRESENCE)
training_data <- training(data_split)
testing_data <- testing(data_split)

# example preprocessing recipe
recipe <- recipe(PRESENCE ~ ., data = training_data) |>
  update_role(lat, lon, U, V, new_role = "ID") |>
  step_mutate(Vel = sqrt(U^2 + V^2), role = "predictor") |>
  step_corr(all_numeric_predictors(), threshold = .95) |>
  step_zv(all_predictors()) |>
  step_normalize(all_numeric_predictors())

# example model: random forest
model <- rand_forest(trees = 15) |>
  set_engine("ranger") |>
  set_mode("classification")

# workflow: bundling preprocessing and model together
workflow <- workflow() |>
  add_recipe(recipe) |>
  add_model(model) |>
  fit(training_data)

workflow
```

## Model Evaluation ##
 
Evaluate the model with whatever tools you desire. Some examples of analyses are below. 

```{r}
test_results <- augment(workflow, testing_data)

dplyr::glimpse(test_results)
```

* `Yardstick` provides methods to easily collect performance metrics.

```{r}
# defining and retrieving desired metrics
pa_metrics <- metric_set(roc_auc, sens, spec, accuracy)
pa_metrics(test_results, 
           truth = PRESENCE, 
           estimate = .pred_class, 
           .pred_1,
           event_level = "second")
```

* By splitting the results table by month, we can collect a monthly performance breakdown.

```{r}
# building a table that contains AUC for each month of predictions
auc_monthly <- count(test_results, MONTH) |>
  bind_cols(AUC = split(test_results, test_results$MONTH) |> 
              lapply(function(x) roc_auc_vec(x$PRESENCE,
                                             x$.pred_1,
                                             event_level = "second")) |>
      unlist()) |>
  mutate(MONTH = as.numeric(MONTH))

# plotting the AUC by month 
ggplot(data = auc_monthly, 
       mapping = aes(x = MONTH, y = AUC)) +
  geom_line() +
  geom_point() +
  scale_x_continuous(name = "Month", 
                     breaks = 1:12, 
                     labels = c("Jan", "Feb", "Mar", "Apr", 
                                "May", "Jun", "Jul", "Aug",
                                "Sep", "Oct", "Nov", "Dec")) +
  scale_y_continuous(name = "AUC", limits = c(.5, 1)) +
  ggtitle("AUC by Month") +
  theme_classic() + 
  theme(panel.grid.major.y = element_line())
```

## Predictions and Plots ##

Now, using `workflow` we can generate and visualize monthly predictions for a desired Brickman scenario. I've created three helper functions to assist with this portion of the modeling process: 

* **`get_predictions()`** takes a workflow and returns a list of monthly predictions for a desired scenario. 
* **`get_value_plots()`** plots presence probabilities in the North Atlantic based off a prediction list. 
* **`get_threshold_plots()`** creates plots shwoing how presence changes between scenarios relative to a desired threshold. 

These three methods are defined in `brickman_walkthrough_help.R`. 

First, generate predictions using `get_predictions()`. 

* Although we trained the model on present-day data, note that I'm still generating present predictions. The training data likely will not cover the entire extent of the Brickman dataset. By generating present predictions, we can see predictions for areas outside of the training data's bounds as well as create a point of reference for how predictions change between present and future scenarios. 

```{r}
source("brickman_walkthrough_help.R")

# predictions for the most extreme climate scenario: RCP85 2075. 
future_preds <- get_predictions(wkf = workflow, # the fitted workflow
                                brickman_vars = VARS, # brickman covariates
                                year = c(NA, 2055, 2075)[3], # year of predictions
                                scenario = c("PRESENT", "RCP45", "RCP85")[3], # scenario for predictions
                                augment_preds = FALSE, # include env covariates
                                verbose = FALSE, 
                                downsample = 3) # higher values = lower resolution
# present predictions
present_preds <- get_predictions(wkf = workflow, 
                                 brickman_vars = VARS, 
                                 year = NA, 
                                 scenario = "PRESENT",
                                 augment_preds = FALSE,
                                 verbose = FALSE,
                                 downsample = 3)
# list of 12 
length(future_preds)

# can index by number or by 3 letter abbreviation of desired month
future_preds[["Oct"]]
```

There are three pre-defined ways to visualize prediction data:

* **Raw**: Plot the predicted presence probability of a scenario. This is best for understanding where the model places presences and absenses. 
* **Difference**: Plot how presence probability changes between two different scenarios. This is best for understanding how raw probabilities shift. 
* **Threshold**: Plot how presence probability shifts relative to a desired threshold. This is best for examining how high-presence areas shift between scenarios. 

Use `get_value_plots()` to retrieve raw or difference plots, and use `get_threshold_plots()` to retrieve threshold plots. Both of these methods return a list of 12 `ggplot` objects named by month. 

```{r}
# retrieving raw predictions for the most extreme scenario
raw_plots <- get_value_plots(future_preds, # prediction data 
                             title = "RCP85 2075 Predicted Presence Probability",
                             pt_size = .3, # size of points in graph
                             xlim = NULL, # optional bounds for plot 
                             ylim = NULL)

# Examining the predicted presence for October
raw_plots[["Oct"]]

# difference plots
difference_plots <- get_value_plots(future_preds,
                                    title = "RCP85 2075 Change in Presence Probability",
                                    pt_size = .3,
                                    xlim = NULL, 
                                    ylim = NULL,
                                    # comparison argument: comparing to present day
                                    comparison_list = present_preds)

# Examining the predicted change in presence for October
# Note that the white area in gulf of maine indicates values beyond the scale
difference_plots[["Oct"]]

# threshold
threshold_plots <- get_threshold_plots(future_preds, # target prediction data
                                       present_preds, # comparison prediction data
                                       threshold = .5, # threshold for presence
                                       title = "Change in Presence (Threshold: .5)",
                                       pt_size = .3,
                                       xlim = NULL,
                                       ylim = NULL)

# Examining how high presence areas shift between present and future 
threshold_plots[["Oct"]]
```
